# ğŸ§ âœ¨ Text-to-Image Generator using Stable Diffusion & Gradio

This project demonstrates how to convert **text prompts into images** using the powerful **Stable Diffusion model** and a simple **Gradio** interface for user interaction.

---

## ğŸš€ Project Overview

- ğŸ”¤ Input: User types a **text prompt** describing an image (e.g., "a futuristic cityscape at sunset")
- ğŸ–¼ï¸ Output: The model generates a **realistic image** matching the description
- âš™ï¸ Powered by **Stable Diffusion** (a state-of-the-art generative model)
- ğŸŒ Frontend built using **Gradio** for easy browser-based interaction

---

## ğŸ› ï¸ Tech Stack

| Tool/Library        | Purpose                         |
|---------------------|----------------------------------|
| **Python**          | Programming language             |
| **Stable Diffusion**| Generative AI model              |
| **Diffusers (ğŸ¤—)**  | Hugging Face interface for models |
| **Transformers**    | Tokenization and model support   |
| **Gradio**          | Web-based UI for model demos     |
| **Torch (PyTorch)** | Backend for model inference      |

---

## âš™ï¸ How It Works

1. The user enters a **text prompt** (e.g., "a cat wearing sunglasses in space")
2. The **Stable Diffusion model** encodes this text into latent representations
3. The model **decodes the representation into a full image**
4. The image is displayed in the **Gradio app**

---





![Image](https://github.com/user-attachments/assets/4604b054-24be-4d19-aedc-583a3abb3a9e)
